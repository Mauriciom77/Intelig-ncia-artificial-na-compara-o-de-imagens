{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Objetivo de circilar/localizar a imagem e realizar uma marcação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importações\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para obter as saídas dos nomes das camadas\n",
    "def get_outputs_names(net):\n",
    "    # Obter os nomes de todas as camadas da rede\n",
    "    layers_names = net.getLayerNames()\n",
    "    # Obter os índices das camadas de saída, i.e., as camadas com saídas não conectadas\n",
    "    out_layers = net.getUnconnectedOutLayers()\n",
    "    \n",
    "    # Verificar se estamos lidando com uma versão mais antiga do OpenCV\n",
    "    if len(out_layers.shape) > 1: \n",
    "        out_layers = out_layers.reshape(-1)\n",
    "\n",
    "    return [layers_names[i - 1] for i in out_layers]\n",
    "\n",
    "# Função para desenhar caixas delimitadoras nos objetos detectados\n",
    "def draw_pred(frame, class_id, conf, left, top, right, bottom, classes):\n",
    "    # Desenhar um retângulo ao redor do objeto detectado\n",
    "    cv2.rectangle(frame, (left, top), (right, bottom), (0, 255, 0), 3)\n",
    "\n",
    "    label = f'{classes[class_id]}: {conf:.2f}'\n",
    "\n",
    "    # Obter o texto tamanho\n",
    "    label_size, base_line = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1)\n",
    "\n",
    "    top = max(top, label_size[1])\n",
    "    cv2.rectangle(frame, (left, top - round(1.5*label_size[1])), (left + round(1.5*label_size[0]), top + base_line), (255, 255, 255), cv2.FILLED)\n",
    "    cv2.putText(frame, label, (left, top), cv2.FONT_HERSHEY_SIMPLEX, 0.75, (0,0,0), 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criando um mode de escolher o veiculo principal considenrando que no fundo da imagem pode haver mais de uma veiculo, a escolha do veiculo principal tem como base o tamanho da imagem e a posição do objeto referente ao centro da foto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_box_score(box, frame_width, frame_height):\n",
    "    # Desempacotar as coordenadas da caixa\n",
    "    left, top, width, height = box\n",
    "\n",
    "    # Calcular a área da caixa (tamanho)\n",
    "    area = width * height\n",
    "\n",
    "    # Calcular o centro da caixa\n",
    "    center_x = left + width / 2\n",
    "    center_y = top + height / 2\n",
    "\n",
    "    # Calcular a distância do centro da caixa até o centro da imagem\n",
    "    center_distance = ((center_x - frame_width / 2) ** 2 + (center_y - frame_height / 2) ** 2) ** 0.5\n",
    "\n",
    "    # Combinação de tamanho e centralidade (pode ajustar os pesos)\n",
    "    score = area / center_distance  # Maior área e menor distância aumentam a pontuação\n",
    "\n",
    "    return score\n",
    "\n",
    "def detect_main_vehicle(frame, boxes, class_ids, confidences, classes):\n",
    "    frame_height, frame_width = frame.shape[:2]\n",
    "\n",
    "    max_score = 0\n",
    "    main_vehicle_idx = -1\n",
    "\n",
    "    for i, box in enumerate(boxes):\n",
    "        if classes[class_ids[i]] == \"car\" or classes[class_ids[i]] == \"truck\":  # Ajuste conforme necessário\n",
    "            score = calculate_box_score(box, frame_width, frame_height)\n",
    "\n",
    "            if score > max_score:\n",
    "                max_score = score\n",
    "                main_vehicle_idx = i\n",
    "\n",
    "    if main_vehicle_idx != -1:\n",
    "        box = boxes[main_vehicle_idx]\n",
    "        left, top, width, height = box\n",
    "        draw_pred(frame, class_ids[main_vehicle_idx], confidences[main_vehicle_idx], left, top, left + width, top + height, classes)\n",
    "    \n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxes_global = [] # declarando a variavel global para pegar a list do boxes\n",
    "\n",
    "def detect_objects(image_path):\n",
    "    \n",
    "    global boxes_global\n",
    "    # Carregar os nomes das classes\n",
    "    classes_file = \"D:\\Pos_IA\\TCC\\yolov3-8\\data\\coco.names\"\n",
    "    with open(classes_file, 'rt') as f:\n",
    "        classes = f.read().rstrip('\\n').split('\\n')\n",
    "\n",
    "    # Carregar a imagem\n",
    "    frame = cv2.imread(image_path)\n",
    "    \n",
    "    # Verificar se a imagem foi carregada corretamente\n",
    "    if frame is None:\n",
    "        print(f\"Erro ao carregar a imagem: {image_path}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "    # Caminho para os arquivos de configuração e pesos do YOLO\n",
    "    model_configuration = \"D:\\Pos_IA\\TCC\\yolov3-8\\cfg\\yolov3.cfg\"\n",
    "    model_weights = \"D:\\Pos_IA\\TCC\\yolov3-8\\weights\\yolov3.weights\"\n",
    "\n",
    "    # Inicializar a rede neural\n",
    "    net = cv2.dnn.readNetFromDarknet(model_configuration, model_weights)\n",
    "    net.setPreferableBackend(cv2.dnn.DNN_BACKEND_OPENCV)\n",
    "    net.setPreferableTarget(cv2.dnn.DNN_TARGET_CPU)\n",
    "\n",
    "    # Criar um blob da imagem e passar pelo modelo\n",
    "    blob = cv2.dnn.blobFromImage(frame, 0.00392, (416, 416), (0, 0, 0), True, crop=False)\n",
    "    net.setInput(blob)\n",
    "    outs = net.forward(get_outputs_names(net))\n",
    "\n",
    "    # Processamento das saídas\n",
    "    frame_height = frame.shape[0]\n",
    "    frame_width = frame.shape[1]\n",
    "    class_ids = []\n",
    "    confidences = []\n",
    "    boxes = []\n",
    "    conf_threshold = 0.5\n",
    "    nms_threshold = 0.4\n",
    "\n",
    "    for out in outs:\n",
    "        for detection in out:\n",
    "            scores = detection[5:]\n",
    "            class_id = np.argmax(scores)\n",
    "            confidence = scores[class_id]\n",
    "            if confidence > conf_threshold:\n",
    "                center_x = int(detection[0] * frame_width)\n",
    "                center_y = int(detection[1] * frame_height)\n",
    "                width = int(detection[2] * frame_width)\n",
    "                height = int(detection[3] * frame_height)\n",
    "                left = int(center_x - width / 2)\n",
    "                top = int(center_y - height / 2)\n",
    "                class_ids.append(class_id)\n",
    "                confidences.append(float(confidence))\n",
    "                boxes.append([left, top, width, height])\n",
    "\n",
    "    #----- com essa parte do codigo eu consigo localizar todos os veiculos da imagem\n",
    "    # # Aplicar non-maxima suppression para remover caixas delimitadoras redundantes\n",
    "    # indices = cv2.dnn.NMSBoxes(boxes, confidences, conf_threshold, nms_threshold)\n",
    "\n",
    "    # # Verificar a forma do array 'indices' e ajustar o loop de acordo\n",
    "    # if len(indices) > 0 and len(indices.shape) == 1:\n",
    "    #     # Se 'indices' for um array 1D (caso comum em versões mais recentes do OpenCV)\n",
    "    #     for i in indices:\n",
    "    #         box = boxes[i]\n",
    "    #         left = box[0]\n",
    "    #         top = box[1]\n",
    "    #         width = box[2]\n",
    "    #         height = box[3]\n",
    "    #         draw_pred(frame, class_ids[i], confidences[i], left, top, left + width, top + height, classes)\n",
    "    # else:\n",
    "    #     # Se 'indices' for um array 2D (como em algumas versões mais antigas do OpenCV)\n",
    "    #     for i in indices:\n",
    "    #         i = i[0]\n",
    "    #         box = boxes[i]\n",
    "    #         left = box[0]\n",
    "    #         top = box[1]\n",
    "    #         width = box[2]\n",
    "    #         height = box[3]\n",
    "    #         draw_pred(frame, class_ids[i], confidences[i], left, top, left + width, top + height, classes)\n",
    "    \n",
    "    # Chamar detect_main_vehicle para destacar o veículo principal\n",
    "    frame = detect_main_vehicle(frame, boxes, class_ids, confidences, classes)\n",
    "    boxes_global = boxes\n",
    "    \n",
    "    return frame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supondo que você tenha uma imagem de teste, você pode chamá-la assim:\n",
    "result_image = detect_objects('D:\\Pos_IA\\TCC\\carrob.jpg')\n",
    "# Salvar a imagem combinada\n",
    "cv2.imwrite('Image_com_deteccao.png', result_image)\n",
    "\n",
    "# Verificar se a imagem resultante é válida antes de exibi-la\n",
    "if result_image is not None:\n",
    "    cv2.imshow(\"Detected Objects\", result_image)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "else:\n",
    "    print(\"Não foi possível processar a imagem.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Função para que seja apagado o fundo e colocar uma outra cor para que seja melhor na identificação do objeto na comparação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isolate_vehicle(image, box, fill_color=(255, 255, 5)):\n",
    "    \"\"\"\n",
    "    Isola o veículo na imagem, alterando o fundo para uma cor única.\n",
    "\n",
    "    Args:\n",
    "    - image: Imagem original.\n",
    "    - box: Caixa delimitadora do veículo principal (x, y, width, height).\n",
    "    - fill_color: Cor do fundo (padrão Laranja florecente).\n",
    "\n",
    "    Returns:\n",
    "    - Imagem com o veículo isolado.\n",
    "    \"\"\"\n",
    "    # Criar uma cópia da imagem\n",
    "    isolated_image = image.copy()\n",
    "\n",
    "    # Criar uma máscara preta do mesmo tamanho da imagem\n",
    "    mask = np.zeros_like(image)\n",
    "\n",
    "    # Obter as coordenadas da caixa delimitadora\n",
    "    x, y, width, height = box\n",
    "\n",
    "    # Preencher a área do veículo na máscara com branco\n",
    "    mask[y:y+height, x:x+width] = [255, 255, 255]\n",
    "\n",
    "    # Aplicar a máscara para isolar o veículo\n",
    "    # isolated_image[np.where(mask == 0)] = fill_color\n",
    "\n",
    "    for c in range(3):  # Para cada canal de cor (RGB)\n",
    "        isolated_image[:, :, c][mask[:, :, c] == 0] = fill_color[c]\n",
    "\n",
    "    return isolated_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1001, 14, 270, 204],\n",
       " [122, 32, 1078, 648],\n",
       " [165, 34, 999, 772],\n",
       " [205, 37, 981, 762],\n",
       " [146, 48, 1038, 811],\n",
       " [166, 58, 1059, 792],\n",
       " [1015, -10, 263, 229],\n",
       " [1020, 0, 252, 232]]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boxes_global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# box = boxes_global\n",
    "#  Recorta e pinta o fundo da imagem de outra cor para facilicar a comparação dos objetos \n",
    "if boxes_global:\n",
    "    # Seleciona a caixa com a maior área\n",
    "    box = max(boxes_global, key=lambda b: b[2] * b[3])\n",
    "else:\n",
    "    print(\"Nenhuma caixa foi detectada.\")\n",
    "    box = None\n",
    "if box:\n",
    "    # Isolar o veículo na imagem\n",
    "    isolated_vehicle_image = isolate_vehicle(result_image, box)\n",
    "\n",
    "    # Exibir a imagem resultante\n",
    "    cv2.imshow(\"Isolated Vehicle\", isolated_vehicle_image)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    # Opcionalmente, salvar a imagem resultante\n",
    "    output_path = 'caminho_para_salvar_imagem_isolada.jpg'\n",
    "    cv2.imwrite(output_path, isolated_vehicle_image)\n",
    "else:\n",
    "    print(\"Não foi possível isolar o veículo. A caixa delimitadora está vazia.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ficou bom os traços "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ficou bom os traços \n",
    "\n",
    "# cria um contor e identifica traços dentro do contorno criado \n",
    "\n",
    "def draw_precise_contour(image, box):\n",
    "    # Extrair a região de interesse (ROI) com base na caixa delimitadora\n",
    "    x, y, w, h = box\n",
    "    roi = image[y:y+h, x:x+w]\n",
    "\n",
    "    # Converter a ROI para escala de cinza e aplicar detecção de bordas\n",
    "    gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)\n",
    "    edges = cv2.Canny(gray, 100, 200)\n",
    "\n",
    "    # Encontrar contornos na ROI\n",
    "    contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Desenhar os contornos na imagem original\n",
    "    cv2.drawContours(image, contours, -1, (0, 255, 0), 3, offset=(x,y))\n",
    "\n",
    "    return image\n",
    "\n",
    "# Supondo que 'image' seja sua imagem original e 'box' a caixa delimitadora\n",
    "image_with_contour = draw_precise_contour(result_image, box)\n",
    "\n",
    "# Exibir a imagem resultante\n",
    "cv2.imshow(\"Image with Precise Contour\", image_with_contour)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supondo que 'image' seja a imagem original e 'box' a caixa delimitadora\n",
    "# image = 'D:\\Pos_IA\\TCC\\carrob.jpg'\n",
    "# image = cv2.imread(image)\n",
    "image = result_image\n",
    "\n",
    "x, y, w, h = box  # Desempacotar a caixa delimitadora\n",
    "roi = image[y:y+h, x:x+w]  # Extrair a região de interesse\n",
    "\n",
    "# Converter para escala de cinza\n",
    "gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Aplicar um desfoque para reduzir o ruído\n",
    "blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "\n",
    "# Detecção de bordas Canny\n",
    "edges = cv2.Canny(blurred, 50, 150)\n",
    "\n",
    "# Encontrar contornos\n",
    "contours, _ = cv2.findContours(edges.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# Filtrar contornos, se necessário, por exemplo, pelo tamanho\n",
    "contours = [cnt for cnt in contours if cv2.contourArea(cnt) > 100]\n",
    "\n",
    "# Desenhar contornos na imagem original\n",
    "cv2.drawContours(image, contours, -1, (0, 255, 0), 2, offset=(x, y))\n",
    "\n",
    "# Exibir a imagem com contornos\n",
    "cv2.imshow(\"Vehicle Contours\", image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image = 'D:\\Pos_IA\\TCC\\carrob.jpg'\n",
    "image = cv2.imread(image)\n",
    "\n",
    "# Supondo que 'image' seja a imagem original e 'box' a caixa delimitadora\n",
    "x, y, w, h = box  # Desempacotar a caixa delimitadora do YOLO\n",
    "roi = image[y:y+h, x:x+w]  # Extrair a região de interesse\n",
    "\n",
    "# Processamento da ROI para encontrar contornos\n",
    "gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)\n",
    "blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "edges = cv2.Canny(blurred, 50, 150)\n",
    "\n",
    "# Encontrar contornos na ROI processada\n",
    "contours, _ = cv2.findContours(edges.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "contours = [cnt for cnt in contours if cv2.contourArea(cnt) > 10]  # Filtrar contornos por área\n",
    "\n",
    "# Desenhar contornos filtrados na imagem original\n",
    "for cnt in contours:\n",
    "    # Ajustar as coordenadas do contorno para a posição original na imagem\n",
    "    cnt += np.array([x, y])\n",
    "    cv2.drawContours(image, [cnt], -1, (0, 255, 0), 2)\n",
    "\n",
    "# Exibir a imagem com contornos\n",
    "cv2.imshow(\"Vehicle Contours\", image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Salvar a imagem resultante\n",
    "cv2.imwrite('imagem_com_contornos.jpg', image)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
